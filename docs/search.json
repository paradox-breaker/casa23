[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Weekly Diary",
    "section": "",
    "text": "Welcome\nThis is my weekly study notes for the CASA0023 course. My undergraduate major was Geographic Information Science, and my thesis focused on vegetation extraction from remote sensing imagery. Therefore, some of my personal reflections may be related to my undergraduate background.\n\n\n\n\nAstola, Heikki, Tuomas Häme, Laura Sirro, Matthieu Molinier, and Jorma Kilpi. 2019. “Comparison of Sentinel-2 and Landsat 8 Imagery for Forest Variable Prediction in Boreal Region.” Remote Sensing of Environment 223: 257–73. https://doi.org/https://doi.org/10.1016/j.rse.2019.01.019.\n\n\nHernández, Daniel, José M. Cecilia, Juan-Carlos Cano, and Carlos T. Calafate. 2022. “Flood Detection Using Real-Time Image Segmentation from Unmanned Aerial Vehicles on Edge-Computing Platform.” Remote Sensing 14 (1). https://doi.org/10.3390/rs14010223.\n\n\nKaplan, Nur Huseyin, Isin Erer, and Deniz Kumlu. 2021. “Image Enhancement Methods for Remote Sensing: A Survey.” In Recent Remote Sensing Sensor Applications, edited by Maged Marghany. Rijeka: IntechOpen. https://doi.org/10.5772/intechopen.98527.\n\n\nMohammadpour, Pegah, Domingos Xavier Viegas, and Carlos Viegas. 2022. “Vegetation Mapping with Random Forest Using Sentinel 2 and GLCM Texture Feature—a Case Study for Lousã Region, Portugal.” Remote Sensing 14 (18). https://doi.org/10.3390/rs14184585.\n\n\nNavalgund, Ranganath R., V. Jayaraman, and P. S. Roy. 2007. “Remote Sensing Applications: An Overview.” Current Science 93 (12): 1747–66. http://www.jstor.org/stable/24102069.\n\n\nRamzan, Zeeshan, Nisar Ahmed, Qurat-ul-Ain Akram, Shahzad Asif, and Muhammad Shahbaz. 2025. “Enhancing Crop Classification Through Remote Sensing: Landsat 8-9 Fusion and Feature Selection.” Research Square Preprint (Version 1). https://doi.org/10.21203/rs.3.rs-5710241/v1.\n\n\nSidhu, Nanki, Edzer Pebesma, and Gilberto Câmara. 2018. “Using Google Earth Engine to Detect Land Cover Change: Singapore as a Use Case.” European Journal of Remote Sensing 51 (1): 486–500. https://doi.org/10.1080/22797254.2018.1451782.\n\n\nSishodia, R. P., R. L. Ray, and S. K. Singh. 2020. “Applications of Remote Sensing in Precision Agriculture: A Review.” Remote Sensing 12: 3136. https://doi.org/10.3390/rs12193136.\n\n\nSpoto, Francois, Omar Sy, Paolo Laberinti, Philippe Martimort, Valerie Fernandez, Olivier Colin, Bianca Hoersch, and Aime Meygret. 2012. “Overview of Sentinel-2.” In 2012 IEEE International Geoscience and Remote Sensing Symposium, 1707–10. https://doi.org/10.1109/IGARSS.2012.6351195.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "wk1.html",
    "href": "wk1.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Summary\nRemote sensing is a science that uses electromagnetic radiation as a medium to identify surface features and apply surface information to relevant fields (Navalgund, Jayaraman, and Roy 2007). Various sensors function like human eyes that can perceive a broader range of spectral bands, providing richer and more extensive ground information, thus laying the foundation for further analysis.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "wk1.html#summary",
    "href": "wk1.html#summary",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1.1 Active and Passive Remote Sensing\nFigure 1.1 and Table 1.1 demonstate the differences between active and passive remote sensing in terms of working principles, advantages and applications.\n\n\n\n\n\n\nFigure 1.1: Principle Differences Between Active and Passive Remote Sensing Source:Link\n\n\n\n\n\n\nTable 1.1: Comparison of Active and Passive Remote Sensing\n\n\n\n\n\n\n\n\n\n\nCategory\nActive Remote Sensing\nPassive Remote Sensing\n\n\n\n\nEnergy Source\nSensor-generated energy\nRelies on surface radiation\n\n\nAdvantages\n\nIndependent of surface radiation, unaffected by lighting conditions.\nCan penetrate clouds, vegetation, etc.\n\n\nCan cover large areas simultaneously.\nHigh revisit rate,capable of providing time-series data\n\n\n\nApplications\nSuitable for all-time, all-weather, and extreme environment measurements\nSuitable for large-scale continuous observation\n\n\n\n\n\n\n\n\n1.1.2 Interaction with Earth’s Surface\nAs Figure 1.2 shows, solar radiation undergoes a series of interactions at the Earth’s surface, such as cloud scattering, surface scattering, and atmospheric absorption. The energy ultimately received by the sensor is the result of these combined processes, representing rich information while also potentially introducing interference to the research. For example, atmospheric correction is required in the preprocessing of remote sensing images because the energy received by the sensor is affected by atmospheric scattering and absorption, leading to reduced image contrast.\n\n\n\n\n\n\nFigure 1.2: Interaction with Earth’s Surface Source: Link\n\n\n\n\n\n1.1.3 Four Types of Resolution\nTypically, the design of remote sensing sensors requires a trade-off between these four types of resolution based on their primary application areas. For example, high spatial resolution often comes at the cost of a smaller coverage area, which results in a longer revisit period, meaning lower temporal resolution. Additionally, due to technical constraints such as data transmission, spatial resolution and spectral resolution cannot be simultaneously maximized.\n\nDefinitions of the Four Types of Resolution in Remote Sensing\n\n\n\n\n\n\nResolution Type\n Definition\n\n\n\n\nSpatial Resolution\nThe smallest ground unit distinguishable by the sensor, which corresponds to the size of a raster pixel.\n\n\nSpectral Resolution\nThe number and width of spectral bands that the sensor can detect.\n\n\nTemporal Resolution\nThe revisit cycle of the sensor.\n\n\nRadiometric Resolution\nThe smallest detectable energy variation by the sensor.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "wk1.html#application",
    "href": "wk1.html#application",
    "title": "1  Introduction",
    "section": "1.2 Application",
    "text": "1.2 Application\nRemote sensing has been widely studied in various fields, including agricultural management, environmental monitoring, geological exploration, climate change research, land planning, and disaster emergency response. The applicability of active and passive remote sensing varies across different research areas. For example, in terrain mapping, passive remote sensing lacks strong penetration capability, making it difficult to acquire exposed terrain information. In contrast, active remote sensing techniques such as LiDAR and SAR can penetrate surface cover and directly measure elevation. Similarly, in vegetation analysis, the spectral characteristics of vegetation align well with solar radiation, allowing passive remote sensing to provide rich spectral information. This makes it easier to calculate vegetation indices and efficiently monitor vegetation changes.\nIn addition, different fields have varying requirements for image resolution. For instance, urban planning requires high spatial resolution to identify fine structures such as roads and buildings. Weather monitoring demands frequent data updates to capture rapidly changing atmospheric conditions. Vegetation analysis relies on abundant spectral information to detect subtle variations in vegetation health. Temperature monitoring requires sensors with high radiometric resolution to capture small temperature differences accurately.\nTaking the application of remote sensing in agriculture as an example, the technology primarily utilized in this field is passive remote sensing, which aims to obtain information about plant growth and health conditions. Remote sensing in agriculture can be categorized into several aspects, including crop identification, growth monitoring, yield estimation, pest and disease control, and irrigation management, all of which help optimize agricultural operations and enhance production efficiency.\nThe advancement of remote sensing technology, particularly improvements in satellite image resolution, has significantly contributed to the development of precision agriculture. For instance, high spatial resolution data provides more detailed ground information, aiding in land cover identification and soil condition monitoring. Meanwhile, hyperspectral imagery captures finer spectral details, such as the quantification of solar-induced chlorophyll fluorescence, which helps estimate photosynthetic activity, reflecting crop nutritional status and stress response capabilities (Sishodia, Ray, and Singh 2020).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "wk1.html#reflection",
    "href": "wk1.html#reflection",
    "title": "1  Introduction",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\n\n1.3.1 Understanding Remote Sensing Sensors\nI find it fascinating to compare the information received by the human eye with that received by remote sensing sensors. Despite experiencing the same Rayleigh scattering, observers at different locations may see different sky colors due to variations in the atmospheric path length of sunlight. Similarly, remote sensing satellites are highly susceptible to atmospheric effects, highlighting the importance of atmospheric correction. However, unlike the three types of cone cells in the human eye that perceive color and detail, remote sensing sensors are not limited to three spectral bands. For instance, the combination of the near-infrared and red bands can effectively distinguish vegetation, presenting a standard false-color representation that differs from true-color imagery.\n\n\n1.3.2 Methods for Balancing the Four Resolutions\nAs mentioned earlier, it is challenging to simultaneously optimize all four types of resolution in a single task. Therefore, in practical applications, multi-source data fusion is often required. For example, to balance spatial and spectral resolution, high-spectral but low-spatial-resolution imagery can be fused with high-spatial-resolution imagery. Additionally, temporal interpolation can be used to integrate high-temporal, low-spatial-resolution data (e.g., MODIS) with low-temporal, high-spatial-resolution data (e.g., Sentinel-2) to generate imagery that balances both temporal and spatial resolution.\n\n\n1.3.3 Future Prospects of Remote Sensing Technology\nAt present, remote sensing technology is evolving toward higher resolution, greater intelligence, and improved efficiency. Enhancing sensor performance while integrating artificial intelligence can significantly improve data processing efficiency and automation. Taking land cover classification as an example, the introduction of machine learning has enhanced classification accuracy and stability. In the future, the development of adaptive classification methods that reduce the need for manual labeling could further enhance the automation and efficiency of remote sensing classification.\n\n\n\n\nAstola, Heikki, Tuomas Häme, Laura Sirro, Matthieu Molinier, and Jorma Kilpi. 2019. “Comparison of Sentinel-2 and Landsat 8 Imagery for Forest Variable Prediction in Boreal Region.” Remote Sensing of Environment 223: 257–73. https://doi.org/https://doi.org/10.1016/j.rse.2019.01.019.\n\n\nHernández, Daniel, José M. Cecilia, Juan-Carlos Cano, and Carlos T. Calafate. 2022. “Flood Detection Using Real-Time Image Segmentation from Unmanned Aerial Vehicles on Edge-Computing Platform.” Remote Sensing 14 (1). https://doi.org/10.3390/rs14010223.\n\n\nKaplan, Nur Huseyin, Isin Erer, and Deniz Kumlu. 2021. “Image Enhancement Methods for Remote Sensing: A Survey.” In Recent Remote Sensing Sensor Applications, edited by Maged Marghany. Rijeka: IntechOpen. https://doi.org/10.5772/intechopen.98527.\n\n\nMohammadpour, Pegah, Domingos Xavier Viegas, and Carlos Viegas. 2022. “Vegetation Mapping with Random Forest Using Sentinel 2 and GLCM Texture Feature—a Case Study for Lousã Region, Portugal.” Remote Sensing 14 (18). https://doi.org/10.3390/rs14184585.\n\n\nNavalgund, Ranganath R., V. Jayaraman, and P. S. Roy. 2007. “Remote Sensing Applications: An Overview.” Current Science 93 (12): 1747–66. http://www.jstor.org/stable/24102069.\n\n\nRamzan, Zeeshan, Nisar Ahmed, Qurat-ul-Ain Akram, Shahzad Asif, and Muhammad Shahbaz. 2025. “Enhancing Crop Classification Through Remote Sensing: Landsat 8-9 Fusion and Feature Selection.” Research Square Preprint (Version 1). https://doi.org/10.21203/rs.3.rs-5710241/v1.\n\n\nSidhu, Nanki, Edzer Pebesma, and Gilberto Câmara. 2018. “Using Google Earth Engine to Detect Land Cover Change: Singapore as a Use Case.” European Journal of Remote Sensing 51 (1): 486–500. https://doi.org/10.1080/22797254.2018.1451782.\n\n\nSishodia, R. P., R. L. Ray, and S. K. Singh. 2020. “Applications of Remote Sensing in Precision Agriculture: A Review.” Remote Sensing 12: 3136. https://doi.org/10.3390/rs12193136.\n\n\nSpoto, Francois, Omar Sy, Paolo Laberinti, Philippe Martimort, Valerie Fernandez, Olivier Colin, Bianca Hoersch, and Aime Meygret. 2012. “Overview of Sentinel-2.” In 2012 IEEE International Geoscience and Remote Sensing Symposium, 1707–10. https://doi.org/10.1109/IGARSS.2012.6351195.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "wk2.html",
    "href": "wk2.html",
    "title": "2  Presentation",
    "section": "",
    "text": "These are the introduction slides for the MSI sensor onboard the Sentinel-2 satellite series.\n\n\n\n\n\n\n\n\nLink\n\n\n\n\nAstola, Heikki, Tuomas Häme, Laura Sirro, Matthieu Molinier, and Jorma Kilpi. 2019. “Comparison of Sentinel-2 and Landsat 8 Imagery for Forest Variable Prediction in Boreal Region.” Remote Sensing of Environment 223: 257–73. https://doi.org/https://doi.org/10.1016/j.rse.2019.01.019.\n\n\nHernández, Daniel, José M. Cecilia, Juan-Carlos Cano, and Carlos T. Calafate. 2022. “Flood Detection Using Real-Time Image Segmentation from Unmanned Aerial Vehicles on Edge-Computing Platform.” Remote Sensing 14 (1). https://doi.org/10.3390/rs14010223.\n\n\nKaplan, Nur Huseyin, Isin Erer, and Deniz Kumlu. 2021. “Image Enhancement Methods for Remote Sensing: A Survey.” In Recent Remote Sensing Sensor Applications, edited by Maged Marghany. Rijeka: IntechOpen. https://doi.org/10.5772/intechopen.98527.\n\n\nMohammadpour, Pegah, Domingos Xavier Viegas, and Carlos Viegas. 2022. “Vegetation Mapping with Random Forest Using Sentinel 2 and GLCM Texture Feature—a Case Study for Lousã Region, Portugal.” Remote Sensing 14 (18). https://doi.org/10.3390/rs14184585.\n\n\nNavalgund, Ranganath R., V. Jayaraman, and P. S. Roy. 2007. “Remote Sensing Applications: An Overview.” Current Science 93 (12): 1747–66. http://www.jstor.org/stable/24102069.\n\n\nRamzan, Zeeshan, Nisar Ahmed, Qurat-ul-Ain Akram, Shahzad Asif, and Muhammad Shahbaz. 2025. “Enhancing Crop Classification Through Remote Sensing: Landsat 8-9 Fusion and Feature Selection.” Research Square Preprint (Version 1). https://doi.org/10.21203/rs.3.rs-5710241/v1.\n\n\nSidhu, Nanki, Edzer Pebesma, and Gilberto Câmara. 2018. “Using Google Earth Engine to Detect Land Cover Change: Singapore as a Use Case.” European Journal of Remote Sensing 51 (1): 486–500. https://doi.org/10.1080/22797254.2018.1451782.\n\n\nSishodia, R. P., R. L. Ray, and S. K. Singh. 2020. “Applications of Remote Sensing in Precision Agriculture: A Review.” Remote Sensing 12: 3136. https://doi.org/10.3390/rs12193136.\n\n\nSpoto, Francois, Omar Sy, Paolo Laberinti, Philippe Martimort, Valerie Fernandez, Olivier Colin, Bianca Hoersch, and Aime Meygret. 2012. “Overview of Sentinel-2.” In 2012 IEEE International Geoscience and Remote Sensing Symposium, 1707–10. https://doi.org/10.1109/IGARSS.2012.6351195.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Presentation</span>"
    ]
  },
  {
    "objectID": "wk3.html",
    "href": "wk3.html",
    "title": "3  Data Correction and Enhancement",
    "section": "",
    "text": "3.1 Summary",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Correction and Enhancement</span>"
    ]
  },
  {
    "objectID": "wk3.html#summary",
    "href": "wk3.html#summary",
    "title": "3  Data Correction and Enhancement",
    "section": "",
    "text": "3.1.1 Data Organization\n\n3.1.1.1 Format Conversion\nIf specific software is required for image analysis, it is necessary to select a format compatible with that software.\n\n\n3.1.1.2 Image Mosaicking\nSince single images usually cover limited areas, and sometimes a study area spans across two adjacent scenes, it is necessary to mosaic two images.\n\n\n\n\n\nfun=“mean” means calculating the average value in overlapping areas.\nThis section selects an area near the city of Huzhou, China. The final true-color image after mosaicking has a smooth transition without noticeable seams.\n\n\n\n\n\nSometimes, when the pixel values in the overlapping areas of two images differ significantly, the seam may become prominent. In such cases, feathering techniques need to be applied.\n\n\n3.1.1.3 Image Clipping\nSince the coverage of remote sensing images is large, processing and analyzing the entire image may result in unnecessarily computation. Therefore, image clipping is necessary.\nFor example, if I want to classify land cover in Anji County, I can use the boundary vector data to clip the image.\n\n\n\nLandsat 9 True-Color Remote Sensing Image of Anji County\n\n\nI can also determine a threshold based on NDVI values to extract vegetation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.1.2 Data Correction\n\n3.1.2.1 Radiometric Calibration\nSince the sensor receives digital signals, it is necessary to convert them to radiometric units with physical significance, such as radiance. The gain and bias can be obtained from the sensor metadata.\n\n\n\n3.1.2.2 Geometric Correction\nGeometric correction mainly consists of two parts:\n\nEstablishing a mapping relationship between the image to be corrected and the reference image based on selected control points.\nResampling the image.\n\nThe choice of resampling method depends on the specific application. For example, nearest neighbor resampling is suitable for classification tasks, while cubic interpolation is more appropriate for image analysis.\n\n\n3.1.2.3 Atmospheric Correction\nAtmospheric correction is the process of removing atmospheric effects to restore surface reflectance. The necessity of atmospheric correction depends on the specific application. For example:\n\nLand cover classification does not necessarily require atmospheric correction.\nQuantitative parameter extraction requires it for accurate results.\n\n\nAbsolute Calibration VS Relative Calibration\n\n\n\n\n\n\n\n\nAbsolute Calibration\nRelative Calibration\n\n\n\n\nObjective\nConvert digital brightness values into scaled surface reflectance.\nNormalize radiometric intensities across different images and bands.\n\n\nMethods\n\nAtmospheric transfer models\nEmpirical Line Calibration\n\n\nDark Object Subtraction\nHistogram Adjustment\nPseudoinvariant Features\n\n\n\nTypical Applications\nTypical Applications\nTime-series analysis.\n\n\n\n\n\n\n3.1.3 Image Enhancement\nImage enhancement refers to the process of improving image quality and highlighting key information using processing techniques. It can be used for smoothing and denoising, edge detection, and contrast enhancement, making images more suitable for observation and analysis.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Correction and Enhancement</span>"
    ]
  },
  {
    "objectID": "wk3.html#application",
    "href": "wk3.html#application",
    "title": "3  Data Correction and Enhancement",
    "section": "3.2 Application",
    "text": "3.2 Application\nRadiometric calibration, geometric correction and atmospheric correction fall within the scope of remote sensing data preprocessing. The flowchart below intuitively illustrates the position of these three steps in practical remote sensing data applications.\n\n\n\n\n\n\n\n\n\nCurrently, many fields that use remote sensing data rely on Level-2 (L2) data because it has already undergone basic radiometric calibration and atmospheric correction, making it ready for direct analysis. For example, in multi-temporal analyses such as land use change and vegetation cover monitoring, standardized Level-2 data eliminates atmospheric interference, enhancing comparability and reducing the need for user preprocessing.\nOf course, not all research requires preprocessed data. For instance, some studies focus on atmospheric analysis or the development and testing of new correction algorithms, in which case more raw data would be more suitable.\nCompared to image correction, the application of image enhancement is relatively more concentrated, primarily focusing on visual enhancement and improving readability. For example, when using ENVI software for land cover classification, if the acquired image has a narrow spectral range that affects manual interpretation, stretching is needed to facilitate land cover recognition and build a reasonable training set. It is important to note that image stretching is mainly used to enhance details and typically does not alter the original pixel values. However, if the enhanced image is to be applied in further analysis, more caution is required, as the enhancement method should improve image contrast and edge information while preserving the original reflectance values (Kaplan, Erer, and Kumlu 2021).\nRamzan et al. (2025) fused Landsat 8 and Landsat 9 imagery to enhance the accuracy of crop classification and applied image enhancement after fusion to emphasize texture variations and spectral differences. Clearly, this step is crucial for precise classification, as it highlights key features and improves subsequent classification accuracy.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Correction and Enhancement</span>"
    ]
  },
  {
    "objectID": "wk3.html#reflection",
    "href": "wk3.html#reflection",
    "title": "3  Data Correction and Enhancement",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\n\n3.3.1 Real-time Processing\nSome application areas, such as emergency response in natural disasters, have high real-time requirements. It is crucial to rapidly acquire and analyze image data of affected areas to improve response efficiency. The widespread adoption of UAVs provides a continuous data input source for real-time processing.\nCurrently, research has demonstrated the feasibility of implementing edge computing on UAVs to directly perform classification tasks, enabling real-time data monitoring. This approach is also applicable to real-time image correction and enhancement, facilitating the efficient execution of subsequent tasks (Hernández et al. 2022). However, this field still faces challenges related to cost and computational overhead. Therefore, further research is needed to optimize algorithms and improve model accuracy.\n\n\n3.3.2 Adaptability and Generality\nThe correction methods for different sensors are not the same. In geometric correction, due to variations in imaging modes among sensors, optical sensors primarily use ground control points (GCPs) and sometimes utilize digital elevation models (DEM) for orthorectification. In contrast, synthetic aperture radar (SAR), due to its side-looking imaging geometry, requires range-Doppler geometric correction.\nFor atmospheric correction, Sentinel-2 employs the 6S model, while hyperspectral data requires band-by-band correction because the large number of spectral bands leads to a greater impact of atmospheric absorption.\nTo maintain high efficiency in dynamic environments or to standardize the correction process for multiple sensors mounted on the same platform, a generalized framework and adaptive modules are needed. With advancements in machine learning and AI algorithms, improvements in adaptability have become possible. However, practical limitations remain, such as the conflict between adaptability and generality—excessive pursuit of generality may lead to insufficient optimization for individual sensors, while emphasizing adaptability too much can increase computational burden.\nOne emerging approach to address this challenge is developing a universal core algorithm while allowing customization through plugins or configuration files, enabling tailored correction methods for different sensors.\n\n\n\n\nAstola, Heikki, Tuomas Häme, Laura Sirro, Matthieu Molinier, and Jorma Kilpi. 2019. “Comparison of Sentinel-2 and Landsat 8 Imagery for Forest Variable Prediction in Boreal Region.” Remote Sensing of Environment 223: 257–73. https://doi.org/https://doi.org/10.1016/j.rse.2019.01.019.\n\n\nHernández, Daniel, José M. Cecilia, Juan-Carlos Cano, and Carlos T. Calafate. 2022. “Flood Detection Using Real-Time Image Segmentation from Unmanned Aerial Vehicles on Edge-Computing Platform.” Remote Sensing 14 (1). https://doi.org/10.3390/rs14010223.\n\n\nKaplan, Nur Huseyin, Isin Erer, and Deniz Kumlu. 2021. “Image Enhancement Methods for Remote Sensing: A Survey.” In Recent Remote Sensing Sensor Applications, edited by Maged Marghany. Rijeka: IntechOpen. https://doi.org/10.5772/intechopen.98527.\n\n\nMohammadpour, Pegah, Domingos Xavier Viegas, and Carlos Viegas. 2022. “Vegetation Mapping with Random Forest Using Sentinel 2 and GLCM Texture Feature—a Case Study for Lousã Region, Portugal.” Remote Sensing 14 (18). https://doi.org/10.3390/rs14184585.\n\n\nNavalgund, Ranganath R., V. Jayaraman, and P. S. Roy. 2007. “Remote Sensing Applications: An Overview.” Current Science 93 (12): 1747–66. http://www.jstor.org/stable/24102069.\n\n\nRamzan, Zeeshan, Nisar Ahmed, Qurat-ul-Ain Akram, Shahzad Asif, and Muhammad Shahbaz. 2025. “Enhancing Crop Classification Through Remote Sensing: Landsat 8-9 Fusion and Feature Selection.” Research Square Preprint (Version 1). https://doi.org/10.21203/rs.3.rs-5710241/v1.\n\n\nSidhu, Nanki, Edzer Pebesma, and Gilberto Câmara. 2018. “Using Google Earth Engine to Detect Land Cover Change: Singapore as a Use Case.” European Journal of Remote Sensing 51 (1): 486–500. https://doi.org/10.1080/22797254.2018.1451782.\n\n\nSishodia, R. P., R. L. Ray, and S. K. Singh. 2020. “Applications of Remote Sensing in Precision Agriculture: A Review.” Remote Sensing 12: 3136. https://doi.org/10.3390/rs12193136.\n\n\nSpoto, Francois, Omar Sy, Paolo Laberinti, Philippe Martimort, Valerie Fernandez, Olivier Colin, Bianca Hoersch, and Aime Meygret. 2012. “Overview of Sentinel-2.” In 2012 IEEE International Geoscience and Remote Sensing Symposium, 1707–10. https://doi.org/10.1109/IGARSS.2012.6351195.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Correction and Enhancement</span>"
    ]
  },
  {
    "objectID": "wk6.html",
    "href": "wk6.html",
    "title": "4  Google Earth Engine",
    "section": "",
    "text": "4.1 Summary\nThe week mainly focuses on Practical examples to analyze functions and operations that may be involved in remote sensing data processing using GEE.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "wk6.html#summary",
    "href": "wk6.html#summary",
    "title": "4  Google Earth Engine",
    "section": "",
    "text": "4.1.1 Loading Data\nIn this case, we select Landsat 8 Collection 2, T1, L2 data and filter it by time and region, using lt (less than) to select images with cloud cover below 10%.\n\nAfter printing, the console shows the image count and their path-row numbers.\n\n\n\n4.1.2 Radiometric Calibration\nUse regular expressions to filter images.\nDifferent scaling factors are applied to reflectance and brightness temperature.\n“True” indicates that the original image bands will be replaced.\n\n\n\n4.1.3 Visualizing Images\nHere, the median of multiple images is computed.\nmin and max control image stretching:\nPixels with values ≤ min (≥ max) are mapped to the darkest (brightest) color.\nValues in between are linearly stretched.\n\n\nThe image is modified to standard false color in the layer settings.\n\n\n\n4.1.4 Mosaic images\nThe mosaic effect here is not ideal, as there is a noticeable stacking effect.\n\n\n\n4.1.5 Clip images\n\n\n\n4.1.6 Texture measures\nSince the reflectance values are small, but .glcmTexture() requires integer values, the data needs to be stretched.\n\nHere, the values are multiplied by 1000.\n{size: 1} specifies a 3×3 window is used.\nSelected texture metrics: contrast and dissimilarity.\n.toUint16() converts the data to 16-bit integers, as GLCM calculations cannot process 32-bit floating-point numbers.\n\n\n\n\n4.1.7 PCA\nPerform some preliminary setup.\nmeanDict.values(bandNames) extracts the mean of each band as a constant image (without spatial variation) for mean centering.\n\nThen, start defining the function.\nConvert the image so that each pixel contains an array storing multi-band values. The default image storage format is not suitable for direct matrix computations.\n\ncovar is an ee.Dictionary containing the covariance matrix and get(‘array’) retrieves it.\ncovarArray.eigen() computes the eigenvalues and eigenvectors.\nThe result is then sliced using eigens.slice(1, 0, 1) (Dimension = 1 (slicing by rows);Start from row 0, excluding subsequent rows)\nConverted into a 1D list, from which the total variance is calculated.\nFinally, the variance contribution rate of each component is computed.\n\ntoArray(1) converts the 1D array into a 2D array (row-wise), making it suitable for matrixMultiply() computations.\n.arrayFlatten([…]) converts the array image into a regular image format, with a list defining the new band names.\nFinally, extra dimensions in PrincipalComponents are removed, bands are renamed, and normalization is applied.\n\nUltimately, the first four principal components explain more than 99.5% of the variance.\n\n\n\n4.1.8 NDVI",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "wk6.html#application",
    "href": "wk6.html#application",
    "title": "4  Google Earth Engine",
    "section": "4.2 Application",
    "text": "4.2 Application\nGEE is a platform for large-scale geospatial data processing and has a wide range of applications across multiple fields, including resource management, environmental monitoring, land use analysis, disaster response, and urban planning. Sidhu, Pebesma, and Câmara (2018) utilized GEE to analyze land use changes in small terrestrial areas of Singapore by generating time series plots of the Enhanced Vegetation Index (EVI). Their study compared the effectiveness of EVI time series products derived from different data sources (MODIS and Landsat), analyzed the causes of EVI value variations, and discussed both the advantages of GEE and the challenges faced when conducting time series analysis on the platform.\nThe study results revealed that:\n\nThe Tuas industrial area has undergone rapid industrialization since 2006, primarily relying on land reclamation techniques for development. In contrast, the forest cover in the Central Catchment Area has remained unaffected by human activities, with EVI fluctuations aligning with the Southeast Asian monsoon cycle, indicating that vegetation changes are primarily driven by monsoonal variations.\nMODIS, while having low spatial resolution, offers high temporal resolution, enabling frequent data acquisition. This makes it effective in capturing subtle land cover changes and seasonal trends. On the other hand, Landsat, despite its high spatial resolution, has poor temporal resolution, making it difficult to track complete change dynamics. Additionally, some dates suffer from data loss due to severe cloud cover.\nThanks to its MapReduce architecture, GEE demonstrates excellent spatial computing capabilities and can rapidly process imagery on a global scale. However, this very architecture also imposes limitations when simultaneously supporting both spatial and temporal analyses. During the Reduce phase—where data from different time points are integrated—a significant amount of data transmission occurs, increasing computational overhead. As a result, even for small terrestrial areas, processing data beyond a certain time range can lead to computation timeouts.\n\n\n\n\nIncrease in Computation Time Until Timeout",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "wk6.html#reflection",
    "href": "wk6.html#reflection",
    "title": "4  Google Earth Engine",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nThrough the hands-on practice and literature review, it becomes evident that GEE offers numerous significant advantages, such as:\n\nBuilt-in access to extensive remote sensing datasets: Users can directly access high-quality remote sensing data, such as Sentinel and Landsat, from the cloud without the need for time-consuming manual downloads and preprocessing. This significantly reduces both time costs and computational storage costs.\nNo need to manually set up a cloud computing environment: Unlike platforms such as GeoTrellis and SciDB, which require users to deploy their own servers or databases, GEE eliminates the need for any computational environment setup. This provides a major advantage for non-specialist users, allowing them to leverage cloud computing without having to learn complex big data processing tools, thus facilitating interdisciplinary research collaboration.\nProvides APIs for direct large-scale data processing: GEE employs a parallel computing architecture that efficiently processes large-scale data. In spatial computations, GEE enables simultaneous calculations for all pixels rather than processing them individually. Additionally, GEE automatically allocates computing resources to optimize task execution. The API is also designed to be simple and efficient, enabling users to perform complex remote sensing analyses with minimal code effort.\n\nIt can be said that GEE is a truly research-friendly and efficient platform, backed by Google’s technical support, ensuring continuous optimization and long-term development potential.\nHowever, as mentioned earlier, GEE has limitations in time-series analysis. In the future, improvements to the MapReduce computing architecture could further enhance its ability to handle time-series analysis, reducing issues such as computational timeouts and improving overall processing efficiency.\n\n\n\n\nAstola, Heikki, Tuomas Häme, Laura Sirro, Matthieu Molinier, and Jorma Kilpi. 2019. “Comparison of Sentinel-2 and Landsat 8 Imagery for Forest Variable Prediction in Boreal Region.” Remote Sensing of Environment 223: 257–73. https://doi.org/https://doi.org/10.1016/j.rse.2019.01.019.\n\n\nHernández, Daniel, José M. Cecilia, Juan-Carlos Cano, and Carlos T. Calafate. 2022. “Flood Detection Using Real-Time Image Segmentation from Unmanned Aerial Vehicles on Edge-Computing Platform.” Remote Sensing 14 (1). https://doi.org/10.3390/rs14010223.\n\n\nKaplan, Nur Huseyin, Isin Erer, and Deniz Kumlu. 2021. “Image Enhancement Methods for Remote Sensing: A Survey.” In Recent Remote Sensing Sensor Applications, edited by Maged Marghany. Rijeka: IntechOpen. https://doi.org/10.5772/intechopen.98527.\n\n\nMohammadpour, Pegah, Domingos Xavier Viegas, and Carlos Viegas. 2022. “Vegetation Mapping with Random Forest Using Sentinel 2 and GLCM Texture Feature—a Case Study for Lousã Region, Portugal.” Remote Sensing 14 (18). https://doi.org/10.3390/rs14184585.\n\n\nNavalgund, Ranganath R., V. Jayaraman, and P. S. Roy. 2007. “Remote Sensing Applications: An Overview.” Current Science 93 (12): 1747–66. http://www.jstor.org/stable/24102069.\n\n\nRamzan, Zeeshan, Nisar Ahmed, Qurat-ul-Ain Akram, Shahzad Asif, and Muhammad Shahbaz. 2025. “Enhancing Crop Classification Through Remote Sensing: Landsat 8-9 Fusion and Feature Selection.” Research Square Preprint (Version 1). https://doi.org/10.21203/rs.3.rs-5710241/v1.\n\n\nSidhu, Nanki, Edzer Pebesma, and Gilberto Câmara. 2018. “Using Google Earth Engine to Detect Land Cover Change: Singapore as a Use Case.” European Journal of Remote Sensing 51 (1): 486–500. https://doi.org/10.1080/22797254.2018.1451782.\n\n\nSishodia, R. P., R. L. Ray, and S. K. Singh. 2020. “Applications of Remote Sensing in Precision Agriculture: A Review.” Remote Sensing 12: 3136. https://doi.org/10.3390/rs12193136.\n\n\nSpoto, Francois, Omar Sy, Paolo Laberinti, Philippe Martimort, Valerie Fernandez, Olivier Colin, Bianca Hoersch, and Aime Meygret. 2012. “Overview of Sentinel-2.” In 2012 IEEE International Geoscience and Remote Sensing Symposium, 1707–10. https://doi.org/10.1109/IGARSS.2012.6351195.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Google Earth Engine</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Astola, Heikki, Tuomas Häme, Laura Sirro, Matthieu Molinier, and Jorma\nKilpi. 2019. “Comparison of Sentinel-2 and Landsat 8 Imagery for\nForest Variable Prediction in Boreal Region.” Remote Sensing\nof Environment 223: 257–73. https://doi.org/https://doi.org/10.1016/j.rse.2019.01.019.\n\n\nHernández, Daniel, José M. Cecilia, Juan-Carlos Cano, and Carlos T.\nCalafate. 2022. “Flood Detection Using Real-Time Image\nSegmentation from Unmanned Aerial Vehicles on Edge-Computing\nPlatform.” Remote Sensing 14 (1). https://doi.org/10.3390/rs14010223.\n\n\nKaplan, Nur Huseyin, Isin Erer, and Deniz Kumlu. 2021. “Image\nEnhancement Methods for Remote Sensing: A Survey.” In Recent\nRemote Sensing Sensor Applications, edited by Maged Marghany.\nRijeka: IntechOpen. https://doi.org/10.5772/intechopen.98527.\n\n\nMohammadpour, Pegah, Domingos Xavier Viegas, and Carlos Viegas. 2022.\n“Vegetation Mapping with Random Forest Using Sentinel 2 and GLCM\nTexture Feature—a Case Study for Lousã Region, Portugal.”\nRemote Sensing 14 (18). https://doi.org/10.3390/rs14184585.\n\n\nNavalgund, Ranganath R., V. Jayaraman, and P. S. Roy. 2007.\n“Remote Sensing Applications: An Overview.” Current\nScience 93 (12): 1747–66. http://www.jstor.org/stable/24102069.\n\n\nRamzan, Zeeshan, Nisar Ahmed, Qurat-ul-Ain Akram, Shahzad Asif, and\nMuhammad Shahbaz. 2025. “Enhancing Crop Classification Through\nRemote Sensing: Landsat 8-9 Fusion and Feature Selection.”\nResearch Square Preprint (Version 1). https://doi.org/10.21203/rs.3.rs-5710241/v1.\n\n\nSidhu, Nanki, Edzer Pebesma, and Gilberto Câmara. 2018. “Using\nGoogle Earth Engine to Detect Land Cover Change: Singapore as a Use\nCase.” European Journal of Remote Sensing 51 (1):\n486–500. https://doi.org/10.1080/22797254.2018.1451782.\n\n\nSishodia, R. P., R. L. Ray, and S. K. Singh. 2020. “Applications\nof Remote Sensing in Precision Agriculture: A Review.” Remote\nSensing 12: 3136. https://doi.org/10.3390/rs12193136.\n\n\nSpoto, Francois, Omar Sy, Paolo Laberinti, Philippe Martimort, Valerie\nFernandez, Olivier Colin, Bianca Hoersch, and Aime Meygret. 2012.\n“Overview of Sentinel-2.” In 2012 IEEE International\nGeoscience and Remote Sensing Symposium, 1707–10. https://doi.org/10.1109/IGARSS.2012.6351195.",
    "crumbs": [
      "References"
    ]
  }
]